// src/Models/test.model.js

import { DataTypes } from "sequelize";
import { sequelize1 } from "../config/sequelize.js";

/**
 * Test Model
 * Stores all metadata related to a generated test
 */
export const Test = sequelize1.define("Test", {
  sl_no:{
    type: DataTypes.INTEGER,
  },
  topic_name: {
    type: DataTypes.STRING,
    allowNull: false,
    comment: "Name of the topic for the test",
  },
  answers: {
    type: DataTypes.JSONB,
    allowNull: true,
    comment: "Correct answers for the test (used for evaluation)",
  }, 
  answers_submitted: {
    type: DataTypes.JSONB,
    allowNull: true,
    comment: "User's submitted answers before evaluation",
  },
  test_id: {
    type: DataTypes.UUID,
    defaultValue: DataTypes.UUIDV4,
    primaryKey: true,
    allowNull: false,
    comment: "Unique identifier for the test",
  },
  question_timings: {
  type: DataTypes.JSONB,
  allowNull: true,
  comment: "Start and end timestamps for each question",
}
,
  user_id: {
    type: DataTypes.UUID,
    allowNull: false,
    comment: "Reference to the user taking the test",
  },
  topic_uuid: {
    type: DataTypes.UUID,
    allowNull: true,
    comment: "Reference to the topic (CatalogueNode) stored as UUID (not enforced by DB-level FK)",
  },
  topics: {
    type: DataTypes.JSONB,
    allowNull: false,
    comment: "Array of topic objects included in this test",
  },
  questions: {
    type: DataTypes.JSONB,
    allowNull: false,
    comment: "Generated questions with metadata (ID, text, options, answers, etc.)",
  }, 
  performance_metrics: {
    type: DataTypes.JSONB,
    allowNull: true,
    comment: "Optional performance metrics post evaluation (accuracy, score breakdown, etc.)",
  },
  test_settings: {
    type: DataTypes.JSONB,
    allowNull: false,
    comment: "Settings used for generation (difficulty, retest_wait, fraud_risk_score etc.)",
  },
  status: {
    type: DataTypes.STRING, // Temporarily use STRING instead of ENUM
    defaultValue: "generated",
    allowNull: false,
    comment: "Current state of the test lifecycle",
  },
  eligible_for_bridger: {
    type: DataTypes.BOOLEAN,
    allowNull: false,
    defaultValue: false,
    comment: "Whether the user is eligible to become a Bridger based on this test",
  },
  result: {
    type: DataTypes.JSONB,
    allowNull: true,
    comment: "Evaluation result (e.g., score, accuracy, time taken, etc.)",
  },

  fraud_flags: {
    type: DataTypes.JSONB,
    allowNull: true,
    comment: "Fraud detection flags (suspicious patterns, duplicate attempts, etc.)",
  },
  cooling_period: {
    type: DataTypes.INTEGER, // store number of days
    allowNull: true,
    comment: "Cooling period in days based on test performance",
  },

payment_id: {
  type: DataTypes.UUID,
  allowNull: false,
  unique: true,
  references: {
    model: {
      tableName: "payments",
      schema: "user",
    },
    key: "payment_id",
  },
  onDelete: "RESTRICT",   // remove test if payment is deleted
  onUpdate: "CASCADE",   // keep in sync if payment_id changes
  comment: "Strict FK link to the unique Payment record for this test",
},



  submitted_at: {
    type: DataTypes.DATE,
    allowNull: true,
    comment: "Timestamp when test was submitted",
  }

  
}, {
  tableName: "tests",
  schema: "user",
  timestamps: true,
  underscored: true,
  comment: "Stores all tests generated by AI engine with metadata, fraud signals, results, and flags"
});
